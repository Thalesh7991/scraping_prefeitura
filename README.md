# Scraper CÃ¢mara de Vereadores - Botucatu

Sistema completo para coleta e anÃ¡lise de dados dos vereadores da CÃ¢mara Municipal de Botucatu.

## ğŸš€ CaracterÃ­sticas

- **Scraping AssÃ­ncrono**: Utiliza `aiohttp` para requisiÃ§Ãµes paralelas eficientes
- **Rate Limiting**: Controle inteligente da taxa de requisiÃ§Ãµes
- **Banco de Dados Otimizado**: PostgreSQL com connection pooling e Ã­ndices
- **Tratamento de Erros**: Sistema robusto com retry automÃ¡tico
- **Logging Completo**: Logs detalhados para monitoramento
- **MÃ©tricas**: Coleta de estatÃ­sticas de performance
- **Modular**: Arquitetura limpa e extensÃ­vel

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- PostgreSQL 12+
- ConexÃ£o com internet

## ğŸ›  InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone <seu-repo>
cd scraping_prefeitura
```

2. Crie um ambiente virtual:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Configure as variÃ¡veis de ambiente:
```bash
cp .env.example .env
# Edite o arquivo .env com suas configuraÃ§Ãµes
```

## âš™ï¸ ConfiguraÃ§Ã£o

Crie um arquivo `.env` na raiz do projeto:

```env
# ConfiguraÃ§Ãµes do Banco de Dados
HOST=localhost
PORT=5432
USER=postgres
PASSWORD=sua_senha
DBNAME=prefeitura

# ConfiguraÃ§Ãµes opcionais do scraping
MIN_YEAR=2021
REQUEST_DELAY=1.0
BATCH_DELAY=10.0
```

## ğŸ¯ Uso

### ExecuÃ§Ã£o Completa
```bash
python -m src.main --mode full
```

### Apenas Dados BÃ¡sicos
```bash
python -m src.main --mode basic
```

### Apenas Proposituras Detalhadas
```bash
python -m src.main --mode detailed
```

### Com NÃ­vel de Log Personalizado
```bash
python -m src.main --mode full --log-level DEBUG
```

## ğŸ“Š Estrutura dos Dados

### Tabelas Principais

1. **vereadores**: InformaÃ§Ãµes bÃ¡sicas dos vereadores
2. **proposituras**: Resumo quantitativo por ano/tipo
3. **proposituras_detalhadas**: Dados detalhados de cada propositura
4. **imagens_vereadores**: Fotos dos vereadores
5. **links_proposituras_vereadores**: Controle de URLs processadas

### Exemplo de Uso ProgramÃ¡tico

```python
import asyncio
from src import ScrapingOrchestrator, db_manager

async def exemplo():
    orchestrator = ScrapingOrchestrator()
    await orchestrator.run_full_scraping()
    
    # Obter estatÃ­sticas
    stats = db_manager.get_statistics()
    print(f"Total de vereadores: {stats['vereadores_count']}")

# Executar
asyncio.run(exemplo())
```

## ğŸ”§ Arquitetura

```
src/
â”œâ”€â”€ __init__.py          # Pacote principal
â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ database.py          # Gerenciamento do banco de dados
â”œâ”€â”€ scraper.py           # LÃ³gica de scraping
â”œâ”€â”€ main.py              # Orquestrador principal
â””â”€â”€ utils.py             # UtilitÃ¡rios e helpers
```

### Principais Classes

- **`CamaraScraper`**: Scraper principal com suporte assÃ­ncrono
- **`DatabaseManager`**: Gerenciador de conexÃµes e operaÃ§Ãµes do BD
- **`ScrapingOrchestrator`**: Orquestrador do processo completo
- **`MetricsCollector`**: Coletor de mÃ©tricas de performance

## ğŸ“ˆ Performance

### Melhorias Implementadas

1. **RequisiÃ§Ãµes AssÃ­ncronas**: 3-5x mais rÃ¡pido que versÃ£o sÃ­ncrona
2. **Connection Pooling**: ReutilizaÃ§Ã£o eficiente de conexÃµes
3. **Batch Inserts**: InserÃ§Ã£o em lote no banco de dados
4. **Rate Limiting**: Evita sobrecarga do servidor
5. **Retry Logic**: RecuperaÃ§Ã£o automÃ¡tica de falhas

### Benchmarks TÃ­picos

- **Coleta bÃ¡sica**: ~2-3 minutos
- **Proposituras resumidas**: ~5-10 minutos
- **Proposituras detalhadas**: ~30-60 minutos (dependendo da quantidade)

## ğŸ” Monitoramento

### Logs
- Logs detalhados salvos em `logs/scraping_YYYYMMDD_HHMMSS.log`
- Diferentes nÃ­veis: DEBUG, INFO, WARNING, ERROR

### MÃ©tricas
- Tempo de execuÃ§Ã£o por operaÃ§Ã£o
- NÃºmero de requisiÃ§Ãµes realizadas
- Taxa de sucesso/erro
- Quantidade de dados coletados

## ğŸ› Tratamento de Erros

- **Retry automÃ¡tico** com backoff exponencial
- **Timeouts configurÃ¡veis** para requisiÃ§Ãµes
- **ValidaÃ§Ã£o de dados** antes da inserÃ§Ã£o
- **Rollback automÃ¡tico** em caso de erro no banco

## ğŸ”„ MigraÃ§Ã£o dos Notebooks

Se vocÃª estÃ¡ vindo dos notebooks antigos:

1. **Ciclo1.ipynb** â†’ `scraper.scrape_vereadores_info()`
2. **Ciclo2.ipynb** â†’ `scraper.scrape_vereadores_images()`
3. **Ciclo3.ipynb** â†’ `database.insert_vereadores()` + melhorias
4. **Ciclo4.ipynb** â†’ `scraper.scrape_proposituras_detalhadas()`
5. **Ciclo5.ipynb** â†’ VersÃ£o assÃ­ncrona completa

## ğŸš€ PrÃ³ximos Passos

### Dashboard (Planejado)
- Interface web com Streamlit/Dash
- GrÃ¡ficos interativos de produtividade
- Filtros por vereador, partido, perÃ­odo
- Comparativos e rankings

### Analytics (Planejado)
- AnÃ¡lise de sentimento das proposituras
- Clustering de temas/assuntos
- PrediÃ§Ã£o de aprovaÃ§Ã£o de projetos
- RelatÃ³rios automatizados

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ“ Contato

Thales Pinto - [seu-email]

Link do Projeto: [https://github.com/seu-usuario/scraping_prefeitura](https://github.com/seu-usuario/scraping_prefeitura)

---

## ğŸ¯ ComparaÃ§Ã£o: Antes vs Depois

### Antes (Notebooks)
- âŒ CÃ³digo duplicado entre notebooks
- âŒ Sem tratamento robusto de erros
- âŒ RequisiÃ§Ãµes sÃ­ncronas lentas
- âŒ Sem logging estruturado
- âŒ ConexÃµes de banco nÃ£o otimizadas
- âŒ DifÃ­cil manutenÃ§Ã£o e extensÃ£o

### Depois (VersÃ£o Refatorada)
- âœ… CÃ³digo modular e reutilizÃ¡vel
- âœ… Tratamento robusto de erros com retry
- âœ… RequisiÃ§Ãµes assÃ­ncronas 3-5x mais rÃ¡pidas
- âœ… Logging completo e mÃ©tricas
- âœ… Connection pooling e batch operations
- âœ… FÃ¡cil manutenÃ§Ã£o e extensÃ£o
- âœ… Pronto para produÃ§Ã£o 